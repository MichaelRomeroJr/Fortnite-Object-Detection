from __future__ import division
import torch 
import torch.nn as nn
from torch.autograd import Variable
import numpy as np
import cv2 
from util import *
import argparse
import os 
import os.path as osp
from darknet import Darknet
import pickle as pkl
import pandas as pd
import random
import time
from time import sleep

from PIL import Image, ImageTk

import CreateOverlay
import ConfidenceCheck

import StreamFromMonitor

def arg_parse():
    """    Parse arguements to the detect module"""
    parser = argparse.ArgumentParser(description='YOLO v3 Detection Module')
    parser.add_argument("--bs", dest = "bs", help = "Batch size", default = 1)
    parser.add_argument("--confidence", dest = "confidence", help = "Object Confidence to filter predictions", default = 0.5)
    parser.add_argument("--nms_thresh", dest = "nms_thresh", help = "NMS Threshhold", default = 0.4)
    parser.add_argument("--cfg", dest = 'cfgfile', help = "Config file", default = "cfg/yolov3.cfg", type = str)
    parser.add_argument("--weights", dest = 'weightsfile', help = "weightsfile", default = "yolov3.weights", type = str)
    parser.add_argument("--reso", dest = 'reso', help =  "Input resolution of the network. Increase to increase accuracy. Decrease to increase speed", default = "416", type = str)
    parser.add_argument("--video", dest = "videofile", help = "Video file to     run detection on", default = "video.avi", type = str)
    return parser.parse_args()
    
args = arg_parse()
batch_size = int(args.bs)
confidence = float(args.confidence)
nms_thesh = float(args.nms_thresh)
start = 0
CUDA = torch.cuda.is_available()

num_classes = 80
classes = load_classes("C:/Users/micha/data/coco.names")

#Set up the neural network #print("Loading network.....")
model = Darknet(args.cfgfile)
model.load_weights(args.weightsfile) #print("Network successfully loaded")

model.net_info["height"] = args.reso
inp_dim = int(model.net_info["height"])
assert inp_dim % 32 == 0 
assert inp_dim > 32

#If there's a GPU availible, put the model on GPU
if CUDA:
    print("WE HAVE CUDA!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    model.cuda()

#Set the model in evaluation mode
model.eval()

def write(x, results, confidencescore):
    #confidencescore = str(ConfidenceCheck.score(x))[7:]
    confidencescore = str(ConfidenceCheck.score(x))[:4]
    c1 = tuple(x[1:3].int())
    c2 = tuple(x[3:5].int())
    img = results    
    cls = int(x[-1])
    color = (55, 19, 148) #color = random.choice(colors)
    score = str(confidencescore)[:4]
    label = "{0}".format(classes[cls]) +' ' + score
    cv2.rectangle(img, c1, c2,color, thickness=10) #cv2.rectangle(img, c1, c2,color, 1)
    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]
    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4
    cv2.rectangle(img, c1, c2,color, -1)
    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);
    return img

#Detection phase  
def run():
    assert cap.isOpened(), 'Cannot capture source'
    FrameCount = 0
    frames = 0  
    start = time.time()
    Frame = 0
    thingy =True
    Running = True
    while Running:
        if thingy:
            ret, frame = cap.read()
            ret = True
            if ret: 
                """StreamFromMonitor reads the moniitor saves it as an image than opens it up as a frame to work with"""
                start = time.time()
                StreamFromMonitor.run() 
                frame = cv2.imread("C:/Users/micha/OneDrive/Desktop/Screen.jpeg")
                img = prep_image(frame, inp_dim)

                #cv2.
                ("a", frame)
                im_dim = frame.shape[1], frame.shape[0]
                im_dim = torch.FloatTensor(im_dim).repeat(1,2)   
                     
                if CUDA:
                    im_dim = im_dim.cuda()
                    img = img.cuda()
        
                with torch.no_grad():
                    output = model(Variable(img, volatile = True), CUDA)
                output = write_results(output, confidence, num_classes, nms_conf = nms_thesh)

                """Display object with second highest confidence score"""
                confidencescore = 0
            
                if type(output) == int:
                    frames += 1
                    cv2.imshow("frame", frame)
                                   
                    key = cv2.waitKey(1)
                    if key & 0xFF == ord('q'):
                        break
                    continue
        
                im_dim = im_dim.repeat(output.size(0), 1)
                scaling_factor = torch.min(416/im_dim,1)[0].view(-1,1)
        
                output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim[:,0].view(-1,1))/2
                output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim[:,1].view(-1,1))/2
        
                output[:,1:5] /= scaling_factor

                for i in range(output.shape[0]):
                    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim[i,0])
                    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim[i,1])
    
                classes = load_classes('C:/Users/micha/data/coco.names')
                colors = pkl.load(open("pallete", "rb"))
            
                list(map(lambda x: write(x, frame, confidencescore), output))
            
                cv2.imshow("frame", frame)
           
                new_im = Image.fromarray(frame)
                SavePath ='D:/YOLOImages/img' + str(FrameCount)
                new_im.save(SavePath, 'JPEG') 
                FrameCount+=1        
            
                """Take image with objects identified and overlay it on monitor with clickable feature"""
                CreateOverlay.run(SavePath)
            
                key = cv2.waitKey(1)
                if key & 0xFF == ord('q'):
                    print("'if key & 0xFF == ord('q')' break")
                    break
                frames += 1
                stop = time.time()
                duration = stop-start
                print("Time per frame: ", duration)
            else:
                break    
        else: #Frames we want to skip
            print('ERROR: thingy = False')
            ret, frame = cap.read()
            if ret:   
                img = prep_image(frame, inp_dim)
                im_dim = frame.shape[1], frame.shape[0]
                im_dim = torch.FloatTensor(im_dim).repeat(1,2)   
    
                list(map(lambda x: write(x, frame), output))
                    
                key = cv2.waitKey(1)
                if key & 0xFF == ord('q'):
                    print("ERROR: thingy = false && 'key & 0xFF == ord('q')'")
                    break
            
            else:
                print("ERROR: thiny = False && ret = False")
                break   
        
        Frame+=1
        Running = True

    return


Detecting = True
while Detecting:
    run()
